{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ki/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "# email module has some useful functions\n",
    "import os, sys, email,re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_summary</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5360</td>\n",
       "      <td>5360</td>\n",
       "      <td>5360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5083</td>\n",
       "      <td>4979</td>\n",
       "      <td>5282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>dokumentation, 2nd level support, windows, sup...</td>\n",
       "      <td>Technischer Support</td>\n",
       "      <td>Projektbeschreibung \\n\\n                      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            skill_summary  \\\n",
       "count                                                5360   \n",
       "unique                                               5083   \n",
       "top     dokumentation, 2nd level support, windows, sup...   \n",
       "freq                                                   17   \n",
       "\n",
       "                      title                                        description  \n",
       "count                  5360                                               5360  \n",
       "unique                 4979                                               5282  \n",
       "top     Technischer Support  Projektbeschreibung \\n\\n                      ...  \n",
       "freq                     23                                                 19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../projectfinder.csv')\n",
    "df.dropna(axis=0, inplace=True)\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skill_summary', 'title', 'description']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = [col for col in df.columns]\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business Intelligence Analyst (m/w) - Tableau Desktop \\r\\n \\r\\n \\r\\nFür ein Kundenprojekt suchen wir Sie als \\r\\n \\r\\n Business Intelligence Analyst (m/w) - Tableau Desktop. \\r\\n \\r\\nDer Kunde hat ein sehr hohes, kontinui ...',\n",
       " 'Konzeption, Customizing sowie Softwareanpassungen mit Talend ESB \\r\\n Implementierung von Softwaresystemen mit Java \\r\\n Analyse sowie Design von Softwarearchitekturen',\n",
       " 'Als Mitglied eines kleinen, dynamischen Teams in München lösen Sie gemeinsam mit den Kollegen die technischen Probleme unseres Referenzkunden.\\r\\n Servicezeiten: Montag - Freitag, von 07:00- 18:00 (zwei Schichten)\\r\\n Entgegennahme, Analyse und Zuordnung ein\\xadge\\xadhen\\xadder Stö\\xadrungen\\r\\n Übernahme und Dokumentation ein\\xadge\\xadhen\\xadder Anfra\\xadgen und Pro\\xadble\\xadme\\r\\n Erste Lösungsansätze per Telefon bzw. Remote\\r\\n Bearbeitung der Anfrage - remote\\r\\n Problemlösung , ggf. Weiter\\xadlei\\xadtung der Anfra\\xadgen an nach\\xadge\\xadla\\xadgerte Fach\\xadab\\xadtei\\xadlungen\\r\\n Priorisierung des Problems\\r\\n Fehlerbehebung für Microsoft Office / Outlook und kun\\xadden\\xadspe\\xadzi\\xadfi\\xadsche Soft\\xadware\\r\\n Unterstützung bei der Pflege der Wis\\xadsens\\xadda\\xadten\\xadbank im Help\\xaddesk Gute Kenntnisse in den aktuellen Win\\xaddows-Be\\xadtriebs\\xadsys\\xadte\\xadmen und MS Office \\r\\n Erfahrung mit Ticket Systemen \\r\\n Client Support \\r\\n Deutsch auf Niveau Muttersprache \\r\\n Gutes Englisch in Wort und Schrift \\r\\n Ausgeprägte Dienst\\xadleis\\xadtungs- und Bera\\xadtungs\\xadori\\xaden\\xadtierung \\r\\n Freundliches und kunden\\xadori\\xaden\\xadtier\\xadtes Tele\\xadfon\\xadver\\xadhalten \\r\\n Selbstständige und sorgfältige Arbeits\\xadweise \\r\\n Hohe Einsatzbereitschaft und Fle\\xadxi\\xadbi\\xadlität \\r\\n Teamfähigkeit',\n",
       " 'Über unseren Kunden: \\n \\xa0 \\n Unser Kunde ist ein IT-Systemhaus, das nationale und internationale Klein- und Großunternehmen betreut und seine Niederlassungen in Deutschland, Österreich und der Schweiz hat. Zur Unterstützung wird ein engagierter  CRM-Consultant (m/w)  auf Projektbasis gesucht. \\n \\xa0 \\n Ihre Aufgaben: \\n \\n     Erstellung von Anforderungskonzepten und Mitwirken in deren Umsetzung \\n     Durchführung von kundenspezifischen Anpassungen in MS Dynamics CRM \\n     Analyse der bestehenden und Design sowie Implementierung neuer CRM Lösungen  \\n     Begleitung der Projektierung und Realisierung von Aufträgen \\n     Durchführen von Coachings und Schulungen  \\n \\n Unsere Anforderungen an Sie: \\n \\n     IT Ausbildung (HTL, Fachhochschule, Universität) oder  mehrjährige Erfahrung  in der  MS CRM Beratung \\n     Kenntnisse in Unternehmensabläufen und betriebswirtschaftlichen Prozessen  \\n     Exzellente Deutschkenntnisse und sehr gute Englischkenntnisse \\n     Wirtschaftliches Denken und hohe Kundenorientierung  \\n     Ergebnisorientierte, effiziente Arbeitsweise \\n \\n Unser Angebot: \\n \\n     Flexible Arbeitszeiten und Möglichkeit auf Arbeiten vom Home-Office \\n     Chance auf persönliche und fachliche Weiterentwicklung \\n     Spannendes, herausforderndes Aufgabengebiet in einem jungen, dynamischen Team  \\n     Expandierendes Unternehmen \\n     Mitarbeiter-Benefits',\n",
       " 'Über unseren Kunden: \\n \\xa0 \\n Unser Kunde ist ein internationales IT Dienstleistungsunternehmen mit Sitz in Wien.\\xa0 \\n \\xa0 \\n Zur sofortigen Unterstützung des bestehenden Teams wird ein erfahrener\\xa0 Java-Backend-Developer (f/m) \\xa0gesucht. \\n \\xa0 \\n Ihre Aufgaben: \\n \\n     Erhebung der Anforderungen \\n     Erstellung von Konzepten und Reports sowie die Dokumentation \\n     Neuentwicklung im Backend-Bereich \\n      Begleitung der Projektierung und Realisierung von Aufträgen \\n     Mitwirkung in allen Phasen des Softwareentwicklungsprozesses \\n \\n Unsere Anforderungen an Sie: \\n \\n      IT Ausbildung (HTL, Fachhochschule, idealerweise Universität) \\n      Erfahrung in der Softwareentwicklung \\n     Backend Know How:\\xa0 Java EE 6/7 (JPA, CDI, EJB), Maven, relationale DBs (z.B. MSSQL, Oracle, DB2), Hibernate, Jenkins \\n     idealer Weise Know How:\\xa0 Ansible, Liquibase, Artifactory, RabbitMQ, Wildfly  \\n     bzw im Frontend Bereich: Angular 4, Typescript, Nginx+ \\n     agiles Mindset  (Erfahrung mit Scrum) \\n      Ergebnisorientierung und Leistungsbereitschaft \\n      Teamfähigkeit und Kreativität \\n \\n Unser Angebot: \\n \\n      spannendes Aufgabengebiet in einem engagierten Team \\n      hohen Grad an Gestaltungsmöglichkeiten Ihres Arbeitsbereiches \\n      Chance auf eine gezielte persönliche Weiterentwicklung \\n      leistungsorientierte Honorierung \\n      neueste Technologien \\n      flexible Arbeitszeiten']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = df['title']\n",
    "description = df['description'].tolist()\n",
    "skill = df['skill_summary']\n",
    "print(type(description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622\n",
      "801\n"
     ]
    }
   ],
   "source": [
    "# load nltk's German stopwords'\n",
    "with open('stopwords-de.txt', 'r') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "print(len(stopwords))\n",
    "stopwords_eng = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(stopwords_eng)\n",
    "print(len(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    #convert text list from list to a string\n",
    "    text_to_string = ','.join(str(v) for v in text)\n",
    "    \n",
    "    # sentence tokenization and lowercasing first, then by word to ensure that punctuation is caught as it's own token\n",
    "    list_of_tokens = [word.lower() for sentence in nltk.sent_tokenize(text_to_string) for word in nltk.word_tokenize(sentence)]\n",
    "    \n",
    "    #extract only alphanumic tokens and add to cleaned_tokens\n",
    "    alphanumeric_tokens = [token for token in list_of_tokens if token.isalnum()]\n",
    "    print(alphanumeric_tokens[:20])\n",
    "    \n",
    "    #stopwords removal\n",
    "    cleaned = [word for word in alphanumeric_tokens if word not in stopwords]\n",
    "    print(cleaned[:20])\n",
    "    \n",
    "    #stemming\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in cleaned]\n",
    "    print(stemmed_tokens[:20])\n",
    "\n",
    "    return stemmed_tokens\n",
    "\n",
    "# this is used only for presentational purposes\n",
    "def tokenize_only(text):\n",
    "    #convert text list from list to a string\n",
    "    text_to_string = ','.join(str(v) for v in text)\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    list_of_tokens = [word.lower() for sent in nltk.sent_tokenize(text_to_string) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    #stopwords removal\n",
    "    cleaned = [word for word in list_of_tokens if word not in stopwords]\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    filtered_tokens = [token for token in cleaned if token.isalnum()]\n",
    "    \n",
    "\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'intelligence', 'analyst', 'tableau', 'desktop', 'für', 'ein', 'kundenprojekt', 'suchen', 'wir', 'sie', 'als', 'business', 'intelligence', 'analyst', 'tableau', 'desktop', 'der', 'kunde', 'hat']\n",
      "['business', 'intelligence', 'analyst', 'tableau', 'desktop', 'kundenprojekt', 'suchen', 'business', 'intelligence', 'analyst', 'tableau', 'desktop', 'kunde', 'hohes', 'kontinui', 'konzeption', 'customizing', 'softwareanpassungen', 'talend', 'esb']\n",
      "['business', 'intelligenc', 'analyst', 'tableau', 'desktop', 'kundenprojekt', 'such', 'business', 'intelligenc', 'analyst', 'tableau', 'desktop', 'kund', 'hoh', 'kontinui', 'konzeption', 'customizing', 'softwareanpass', 'talend', 'esb']\n"
     ]
    }
   ],
   "source": [
    "stemmed_text = tokenize_and_stem(description)\n",
    "tokenized_text = tokenize_only(description)\n",
    "#for word in description:\n",
    " #   stemmed_word = tokenize_and_stem(word) #for each item in 'synopses', tokenize/stem\n",
    "  #  all_tokenized = tokenize_only(word)\n",
    "   # stemmed_text.extend(stemmed_word) #extend the 'totalvocab_stemmed' list\n",
    "    #tokenized_text.extend(all_tokenized)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 562931 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': tokenized_text}, index = stemmed_text)\n",
    "print('there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intelligenc</th>\n",
       "      <td>intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst</th>\n",
       "      <td>analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tableau</th>\n",
       "      <td>tableau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desktop</th>\n",
       "      <td>desktop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    words\n",
       "business         business\n",
       "intelligenc  intelligence\n",
       "analyst           analyst\n",
       "tableau           tableau\n",
       "desktop           desktop"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['wahr'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<5360x31978 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 490000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "X = vectorizer.fit_transform(description)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 5\n",
    "model = KMeans(n_clusters=true_k)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "sap\n",
      "bewerben\n",
      "abap\n",
      "direkt\n",
      "melden\n",
      "berater\n",
      "fi\n",
      "erfahrung\n",
      "kenntnisse\n",
      "hana\n",
      "\n",
      "Cluster 1\n",
      "contractor\n",
      "https\n",
      "impressum\n",
      "www\n",
      "de\n",
      "münchen\n",
      "informationen\n",
      "frankfurt\n",
      "main\n",
      "betroffenenrechte\n",
      "\n",
      "Cluster 2\n",
      "hays\n",
      "kontakt\n",
      "passende\n",
      "bewerben\n",
      "positionen\n",
      "profitieren\n",
      "kostenfrei\n",
      "erfahrung\n",
      "vorteile\n",
      "aufgaben\n",
      "\n",
      "Cluster 3\n",
      "experience\n",
      "bewerben\n",
      "knowledge\n",
      "project\n",
      "development\n",
      "data\n",
      "skills\n",
      "sap\n",
      "looking\n",
      "working\n",
      "\n",
      "Cluster 4\n",
      "bewerben\n",
      "direkt\n",
      "melden\n",
      "kenntnisse\n",
      "erfahrung\n",
      "java\n",
      "entwicklung\n",
      "kunden\n",
      "projekt\n",
      "entwickler\n"
     ]
    }
   ],
   "source": [
    "for i in range(true_k):\n",
    "    print()\n",
    "    print(f'Cluster {i}')\n",
    "    \n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(terms[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Prediction\")\n",
    "X = vectorizer.transform([\"Produktumfeld der Firma VMWARE: Airwatch (sehr gute Kenntnisse)Netzwerktechnik: LAN, DMZ, Rechenzentrum (Vertiefte Kenntnisse) MS-Office Tools: Word, Excel, Visio, Powerpoint (Vertiefte Kenntnisse) Bereitschaft zur Sicherheitsüberprüfung Level 2 (Ü2)\"])\n",
    "predicted = model.predict(X)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
